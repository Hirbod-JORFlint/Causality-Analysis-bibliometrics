df <- read.csv("E:/Dars/Liu Thesis/Reports/Causality Analysis/Department of mathematics/math.csv", encoding="UTF-8")
View(df)
library(bnlearn)
library(dplyr)
library(stringr)
separator <- ';'
df <- read.csv("E:/Dars/Liu Thesis/Reports/Causality Analysis/stat&machine.csv")
keyword_column <- 'Keywords'
A_num <- 2
# Compute co-occurrences
df <- df %>%
select(PID, Year, Keywords) %>%
filter(!is.na(.data[[keyword_column]]), .data[[keyword_column]] != "")
# Convert lists of keywords to tuples
df[[keyword_column]] <- lapply(df[[keyword_column]], function(x) {
keywords <- unlist(strsplit(tolower(x), separator))
trimws(keywords)  # Remove leading and trailing whitespaces
})
# Compute co-occurrences
co_occurrences <- table(unlist(lapply(df[[keyword_column]], function(x) {
if(length(x) >= 2) {
combn(sort(x), 2, paste, collapse = "::")
} else {
character(0)  # Return empty character vector if less than 2 keywords
}
})))
co_occurrences <- sort(co_occurrences, decreasing = TRUE)
# Extract edges from co-occurrences
edges <- as.data.frame(matrix(names(co_occurrences), ncol = 1, byrow = TRUE))
# Create a Bayesian Network from the co-occurrences
bn <- empty.graph(nodes = unique(unlist(df[[keyword_column]])))
View(edges)
# Use lapply to iterate over edges
lapply(1:nrow(edges), function(i) {
edge <- unlist(strsplit(as.character(edges[i, ]), "::"))  # Corrected parsing of edge
if (length(edge) == 2 && edge[1] != edge[2]) {  # Ensure from and to are different
bn <<- set.arc(bn, from = edge[1], to = edge[2])
}
})
# Create a Bayesian Network from the co-occurrences
bn <- empty.graph(nodes = unique(unlist(df[[keyword_column]])))
View(bn)
# Use lapply to iterate over edges
lapply(1:nrow(edges), function(i) {
edge <- unlist(strsplit(as.character(edges[i, ]), "::"))  # Corrected parsing of edge
if (length(edge) == 2 && edge[1] != edge[2]) {  # Ensure from and to are different
bn <- set.arc(bn, from = edge[1], to = edge[2])
}
})
# Extract edges from co-occurrences
edges <- as.data.frame(matrix(names(co_occurrences), ncol = 1, byrow = TRUE))
# Create a Bayesian Network from the co-occurrences
bn <- empty.graph(nodes = unique(unlist(df[[keyword_column]])))
# Use lapply to iterate over edges
lapply(1:nrow(edges), function(i) {
edge <- unlist(strsplit(as.character(edges[i, ]), "::"))  # Corrected parsing of edge
if (length(edge) == 2 && edge[1] != edge[2]) {  # Ensure from and to are different
bn <- set.arc(bn, from = edge[1], to = edge[2])
}
})
View(bn)
# Use lapply to iterate over edges
lapply(1:nrow(edges), function(i) {
edge <- unlist(strsplit(as.character(edges[i, ]), "::"))  # Corrected parsing of edge
if (length(edge) == 2 && edge[1] != edge[2]) {  # Ensure from and to are different
bn <<- set.arc(bn, from = edge[1], to = edge[2])
}
})
View(bn)
# Prepare the data for the model
unikeywords <- unique(unlist(df[[keyword_column]]))
data <- matrix(0, nrow = nrow(df), ncol = length(unikeywords),
dimnames = list(NULL, unikeywords))
# Use apply to iterate over rows
apply(df[[keyword_column]], 1, function(x) {
data[cbind(seq_along(x), match(x, unikeywords))] <<- 1
})
data <- data.frame(matrix(0, nrow = nrow(df), ncol = length(unique(unlist(df[[keyword_column]])))))
colnames(data) <- unique(unlist(df[[keyword_column]]))
for (i in 1:nrow(df)) {
keywords <- unique(unlist(df[[keyword_column]][i]))  # Unlist and remove duplicates
data[i, keywords] <- 1
}
View(data)
rm(data)
# Prepare the data for the model
unikeywords <- unique(unlist(df[[keyword_column]]))
data <- data.frame(matrix(0, nrow = nrow(df), ncol = length(unikeywords)))
View(data)
colnames(data) <- unikeywords
View(data)
unique_keywords <- unique(unlist(df[[keyword_column]]))
# Initialize data frame
data <- data.frame(matrix(0, nrow = nrow(df), ncol = length(unique_keywords)))
View(data)
colnames(data) <- unique_keywords
