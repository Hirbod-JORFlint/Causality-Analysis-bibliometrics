df <- read.csv("E:/Dars/Liu Thesis/Reports/Causality Analysis/stat&machine.csv")
View(df)
library(bnlearn)
library(dplyr)
separator <- ';'
df <- read.csv("E:/Dars/Liu Thesis/Reports/Causality Analysis/stat&machine.csv")
keyword_column <- 'Keywords'
A_num <- 2
# Compute co-occurrences
df <- df %>%
select(PID, Year, Keywords) %>%
filter(!is.na(.data[[keyword_column]]), .data[[keyword_column]] != "")
# Convert lists of keywords to tuples
df[[keyword_column]] <- lapply(df[[keyword_column]], function(x) {
keywords <- unlist(strsplit(tolower(x), separator))
trimws(keywords)  # Remove leading and trailing whitespaces
})
# Compute co-occurrences
co_occurrences <- table(unlist(lapply(df[[keyword_column]], function(x) {
if(length(x) >= 2) {
combn(sort(x), 2, paste, collapse = "::")
} else {
character(0)  # Return empty character vector if less than 2 keywords
}
})))
co_occurrences <- sort(co_occurrences, decreasing = TRUE)
# Extract edges from co-occurrences
edges <- as.data.frame(matrix(names(co_occurrences), ncol = 1, byrow = TRUE))
# Create a Bayesian Network from the co-occurrences
bn <- empty.graph(nodes = unique(unlist(df[[keyword_column]])))
#Use lapply to iterate over edges
invisible(lapply(1:nrow(edges), function(i) {
edge <- unlist(strsplit(as.character(edges[i, ]), "::"))  # Corrected parsing of edge
if (length(edge) == 2 && edge[1] != edge[2]) {  # Ensure from and to are different
if (is.character(edge[1]) && is.character(edge[2])) {  # Check if both edges are character strings
if (edge[1] %in% nodes(bn) && edge[2] %in% nodes(bn)) {  # Check if both nodes exist in the bn object
bn <<- set.arc(bn, from = edge[1], to = edge[2])
} else {
print(paste("Node not found in bn:", edge[1], "or", edge[2]))
}
} else {
print(paste("Edge is not a character string:", edge[1], "or", edge[2]))
}
}
}))
# Prepare the data for the model
data <- data.frame(matrix(0, nrow = nrow(df), ncol = length(unique(unlist(df[[keyword_column]])))))
colnames(data) <- unique(unlist(df[[keyword_column]]))
for (i in 1:nrow(df)) {
keywords <- unique(unlist(df[[keyword_column]][i]))  # Unlist and remove duplicates
data[i, keywords] <- 1
}
write.csv(data, file = "gg.csv")
# Perform parameter learning
fitted_bn <- bn.fit(bn, data = data)
View(bn)
View(fitted_bn)
View(fitted_bn)
View(bn)
View(fitted_bn)
